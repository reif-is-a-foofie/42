"""Moroni - The NLP Brain for 42

Moroni provides intelligent NLP analysis using OpenAI with cost optimization.
Acts as the brain layer between missions and Steve's execution.
"""

import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import openai
from loguru import logger

from ..infra.utils.config import load_config


@dataclass
class SearchStrategy:
    """Intelligent search strategy generated by Moroni."""
    primary_queries: List[str]
    secondary_queries: List[str]
    focus_domains: List[str]
    content_types: List[str]  # "research", "doctrine", "news", "academic"
    search_depth: str  # "shallow", "deep", "comprehensive"
    reasoning: str


@dataclass
class ContentAnalysis:
    """Analysis of content quality and relevance."""
    quality_score: float  # 0.0 - 1.0
    relevance_score: float  # 0.0 - 1.0
    content_type: str
    key_topics: List[str]
    learning_potential: float  # 0.0 - 1.0
    reasoning: str


@dataclass
class LearningInsight:
    """Insights for improving future searches."""
    new_keywords: List[str]
    new_domains: List[str]
    search_improvements: List[str]
    content_gaps: List[str]
    reasoning: str


class Moroni:
    """The NLP Brain - Provides intelligent analysis and decision making."""
    
    def __init__(self):
        """Initialize Moroni with OpenAI configuration."""
        config = load_config()
        self.openai_client = openai.OpenAI(api_key=config.openai_api_key)
        self.model = "gpt-3.5-turbo"  # Cost-effective model
        self.max_tokens = 500  # Keep responses concise
        self.temperature = 0.3  # Consistent, focused responses
        
        # Cost tracking
        self.total_tokens_used = 0
        self.total_cost = 0.0
        
        logger.info("ðŸ§  Moroni initialized - NLP Brain ready")
    
    def analyze_mission(self, objective: str, keywords: List[str], domains: List[str]) -> SearchStrategy:
        """Analyze mission objective and generate intelligent search strategy."""
        try:
            prompt = f"""
            Analyze this mission objective and create an intelligent search strategy.
            
            Mission: {objective}
            Keywords: {', '.join(keywords)}
            Domains: {', '.join(domains)}
            
            Generate a search strategy that includes:
            1. 3-5 primary search queries (most important)
            2. 3-5 secondary search queries (broader context)
            3. Focus domains to prioritize
            4. Content types to target (research, doctrine, news, academic)
            5. Search depth (shallow=basic info, deep=detailed analysis, comprehensive=exhaustive)
            6. Brief reasoning for the strategy
            
            Respond in JSON format:
            {{
                "primary_queries": ["query1", "query2"],
                "secondary_queries": ["query3", "query4"],
                "focus_domains": ["domain1", "domain2"],
                "content_types": ["research", "doctrine"],
                "search_depth": "deep",
                "reasoning": "brief explanation"
            }}
            """
            
            response = self._call_openai(prompt, "mission_analysis")
            
            # Parse JSON response
            strategy_data = json.loads(response)
            return SearchStrategy(
                primary_queries=strategy_data.get("primary_queries", []),
                secondary_queries=strategy_data.get("secondary_queries", []),
                focus_domains=strategy_data.get("focus_domains", []),
                content_types=strategy_data.get("content_types", []),
                search_depth=strategy_data.get("search_depth", "deep"),
                reasoning=strategy_data.get("reasoning", "")
            )
            
        except Exception as e:
            logger.error(f"Failed to analyze mission: {e}")
            # Fallback to basic strategy
            return SearchStrategy(
                primary_queries=keywords[:3],
                secondary_queries=keywords[3:],
                focus_domains=domains,
                content_types=["research"],
                search_depth="deep",
                reasoning="Fallback strategy due to analysis failure"
            )
    
    def analyze_search_results(self, results: List[Dict[str, Any]], mission_objective: str) -> List[ContentAnalysis]:
        """Analyze search results for quality and relevance."""
        try:
            # Batch analyze for cost efficiency
            batch_size = 5
            analyses = []
            
            for i in range(0, len(results), batch_size):
                batch = results[i:i + batch_size]
                
                prompt = f"""
                Analyze these search results for quality and relevance to the mission.
                
                Mission: {mission_objective}
                
                Results to analyze:
                {json.dumps(batch, indent=2)}
                
                For each result, provide:
                1. Quality score (0.0-1.0) - based on source authority, content depth
                2. Relevance score (0.0-1.0) - how well it matches mission
                3. Content type (research, doctrine, news, academic, other)
                4. Key topics mentioned
                5. Learning potential (0.0-1.0) - how much new knowledge it provides
                6. Brief reasoning
                
                Respond in JSON format:
                {{
                    "analyses": [
                        {{
                            "quality_score": 0.8,
                            "relevance_score": 0.9,
                            "content_type": "doctrine",
                            "key_topics": ["topic1", "topic2"],
                            "learning_potential": 0.7,
                            "reasoning": "brief explanation"
                        }}
                    ]
                }}
                """
                
                response = self._call_openai(prompt, "content_analysis")
                analysis_data = json.loads(response)
                
                for analysis in analysis_data.get("analyses", []):
                    analyses.append(ContentAnalysis(
                        quality_score=analysis.get("quality_score", 0.5),
                        relevance_score=analysis.get("relevance_score", 0.5),
                        content_type=analysis.get("content_type", "other"),
                        key_topics=analysis.get("key_topics", []),
                        learning_potential=analysis.get("learning_potential", 0.5),
                        reasoning=analysis.get("reasoning", "")
                    ))
            
            return analyses
            
        except Exception as e:
            logger.error(f"Failed to analyze search results: {e}")
            # Fallback to basic analysis
            return [
                ContentAnalysis(
                    quality_score=0.5,
                    relevance_score=0.5,
                    content_type="other",
                    key_topics=[],
                    learning_potential=0.5,
                    reasoning="Fallback analysis due to failure"
                )
                for _ in results
            ]
    
    def generate_learning_insights(self, high_quality_content: List[ContentAnalysis], mission_objective: str) -> LearningInsight:
        """Generate insights for improving future searches."""
        try:
            # Extract key information from high-quality content
            all_topics = []
            all_domains = []
            
            for content in high_quality_content:
                all_topics.extend(content.key_topics)
            
            prompt = f"""
            Based on high-quality content found, generate insights for improving future searches.
            
            Mission: {mission_objective}
            High-quality content topics: {', '.join(set(all_topics))}
            
            Generate insights for:
            1. New keywords to add to search strategy
            2. New domains to explore
            3. Search improvements (query patterns, filters)
            4. Content gaps identified
            5. Brief reasoning
            
            Respond in JSON format:
            {{
                "new_keywords": ["keyword1", "keyword2"],
                "new_domains": ["domain1", "domain2"],
                "search_improvements": ["improvement1", "improvement2"],
                "content_gaps": ["gap1", "gap2"],
                "reasoning": "brief explanation"
            }}
            """
            
            response = self._call_openai(prompt, "learning_insights")
            insight_data = json.loads(response)
            
            return LearningInsight(
                new_keywords=insight_data.get("new_keywords", []),
                new_domains=insight_data.get("new_domains", []),
                search_improvements=insight_data.get("search_improvements", []),
                content_gaps=insight_data.get("content_gaps", []),
                reasoning=insight_data.get("reasoning", "")
            )
            
        except Exception as e:
            logger.error(f"Failed to generate learning insights: {e}")
            return LearningInsight(
                new_keywords=[],
                new_domains=[],
                search_improvements=[],
                content_gaps=[],
                reasoning="Fallback insights due to analysis failure"
            )
    
    def _call_openai(self, prompt: str, operation: str) -> str:
        """Make OpenAI API call with cost tracking."""
        try:
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are Moroni, an intelligent NLP brain that analyzes missions and content. Provide concise, accurate analysis in JSON format."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            # Track usage
            usage = response.usage
            self.total_tokens_used += usage.total_tokens
            
            # Estimate cost (GPT-3.5-turbo pricing)
            cost_per_1k_tokens = 0.002  # Approximate
            cost = (usage.total_tokens / 1000) * cost_per_1k_tokens
            self.total_cost += cost
            
            logger.debug(f"ðŸ§  Moroni {operation}: {usage.total_tokens} tokens, ${cost:.4f}")
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"OpenAI API call failed: {e}")
            raise
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """Get usage statistics for cost monitoring."""
        return {
            "total_tokens": self.total_tokens_used,
            "total_cost": self.total_cost,
            "model": self.model,
            "last_updated": datetime.now().isoformat()
        } 